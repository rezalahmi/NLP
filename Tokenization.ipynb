{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3b67af7-270e-4521-8fd8-46dfe686602e",
   "metadata": {},
   "source": [
    "Tokenization Methods Using NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fb78482-f622-43ab-b6bb-e5f51e08374c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e06c496-8302-426c-afb7-7b8c56e5171c",
   "metadata": {},
   "source": [
    "Word tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8e406af-6ac2-41e7-b59a-5176470e6657",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d70ab3d-9517-4c58-b710-74790ed04488",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [WinError 10051] A\n",
      "[nltk_data]     socket operation was attempted to an unreachable\n",
      "[nltk_data]     network>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08bea786-360b-4f41-9ba3-1e1f80f71877",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"He's a German Shepherd. They are some of the smartest dogs!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "710c1362-8c9d-41be-aa89-90207e552acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['He',\n",
       " \"'s\",\n",
       " 'a',\n",
       " 'German',\n",
       " 'Shepherd',\n",
       " '.',\n",
       " 'They',\n",
       " 'are',\n",
       " 'some',\n",
       " 'of',\n",
       " 'the',\n",
       " 'smartest',\n",
       " 'dogs',\n",
       " '!']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e015443-512b-4ae7-9c5a-0ae0af624b8a",
   "metadata": {},
   "source": [
    "Sentence tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3a15df6-b916-49ef-b952-3e3e92542528",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7c26588-b5bd-450f-9748-042b64a82a07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Natural Language Toolkit, or more commonly NLTK, is a suite of libraries and programs for symbolic and statistical natural language processing (NLP) for English written in the Python programming language.',\n",
       " 'It was developed by Steven Bird and Edward Loper in the Department of Computer and Information Science at the University of Pennsylvania.',\n",
       " 'NLTK includes graphical demonstrations and sample data.',\n",
       " 'It is accompanied by a book that explains the underlying concepts behind the language processing tasks supported by the toolkit, plus a cookbook.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article = '''The Natural Language Toolkit, or more commonly NLTK, is a suite of libraries and programs for symbolic and statistical natural language processing (NLP) for English written in the Python programming language. It was developed by Steven Bird and Edward Loper in the Department of Computer and Information Science at the University of Pennsylvania. NLTK includes graphical demonstrations and sample data. It is accompanied by a book that explains the underlying concepts behind the language processing tasks supported by the toolkit, plus a cookbook.'''\n",
    "sent_tokenize(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6fc435f-07a4-4775-a4eb-f512d8df873f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['کرج در کوهپایه\\u200cهای البرز مرکزی با وسعت ۱۶۰ کیلومتر مربع قرار دارد.',\n",
       " 'کرج تا قبل از تشکیل استان البرز در سال ۱۳۸۹ جزو استان تهران بود؛ با تشکیل استان البرز کرج به عنوان مرکز استان البرز قرار گرفت.',\n",
       " 'این شهر به علت موقعیت جغرافیایی مناسب، داشتن شهرک\\u200cهای صنعتی ، موقعیت اقتصادی و همجواری با کلانشهر تهران بسیار مهاجرپذیر است.',\n",
       " 'کرج پس از تهران بزرگ\\u200cترین شهر مهاجرپذیر ایران است و به همین دلیل به آن لقب «ایران کوچک» داده شده\\u200cاست.',\n",
       " 'همچنین جمعیت این شهر نسبت به سایر شهرهای بزرگ ایران جوان\\u200cتر است، و بالاترین میزان رشد موالید یا زاد و ولد را به خود اختصاص داده\\u200cاست.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persian_article = '''کرج در کوهپایه‌های البرز مرکزی با وسعت ۱۶۰ کیلومتر مربع قرار دارد. کرج تا قبل از تشکیل استان البرز در سال ۱۳۸۹ جزو استان تهران بود؛ با تشکیل استان البرز کرج به عنوان مرکز استان البرز قرار گرفت. این شهر به علت موقعیت جغرافیایی مناسب، داشتن شهرک‌های صنعتی ، موقعیت اقتصادی و همجواری با کلانشهر تهران بسیار مهاجرپذیر است. کرج پس از تهران بزرگ‌ترین شهر مهاجرپذیر ایران است و به همین دلیل به آن لقب «ایران کوچک» داده شده‌است. همچنین جمعیت این شهر نسبت به سایر شهرهای بزرگ ایران جوان‌تر است، و بالاترین میزان رشد موالید یا زاد و ولد را به خود اختصاص داده‌است.'''\n",
    "sent_tokenize(persian_article)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721f29da-8b65-4450-b2aa-feb762f160d8",
   "metadata": {},
   "source": [
    "Contraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "add4dc9c-b3fb-4456-a04b-c79776f50ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c3bc766-b8bb-4f5a-8f56-908910733200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I am you are she is cannot was not\n"
     ]
    }
   ],
   "source": [
    "contract_text = \"I'm you're she's can't wasn't\"\n",
    "out_put_text = \"\"\n",
    "for word in contract_text.split():\n",
    "    out_put_text += ' ' + contractions.fix(word)\n",
    "print(out_put_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
